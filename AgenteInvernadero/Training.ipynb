{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943cd107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import io\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e96e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../Models\"\n",
    "DATASETS = \"../DataSets\"\n",
    "ARCHIVO = None\n",
    "MODEL = os.path.join(PATH, \"invernadero.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c713210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback para mostrar el progreso del entrenamiento al final de cada época.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f\"Época {self.epoch + 1}/{model.epochs} finalizada.\")\n",
    "        self.epoch += 1\n",
    "\n",
    "# 1. Funciones de extracción y preparación de texto\n",
    "def extraer_texto(archivo, datasets_dir):\n",
    "    \"\"\"\n",
    "    Extrae texto de un archivo específico (.pdf o .txt) o de todos los archivos \n",
    "    (.pdf o .txt) en un directorio si 'archivo' es None.\n",
    "    Devuelve una única cadena con el texto extraído (concatenado si son múltiples archivos).\n",
    "    \"\"\"\n",
    "    \n",
    "    def _leer_pdf(ruta_completa):\n",
    "        contenido = \"\"\n",
    "        try:\n",
    "            laparams = LAParams(\n",
    "                line_margin=0.4, \n",
    "                char_margin=3.5, \n",
    "                word_margin=0.2, \n",
    "                boxes_flow=0.5\n",
    "            )\n",
    "            contenido = extract_text(ruta_completa, laparams=laparams)\n",
    "        except Exception as e:\n",
    "            print(f\"ADVERTENCIA: No se pudo leer el archivo PDF '{ruta_completa}' con pdfminer.six. Causa: {e}\")\n",
    "        return contenido\n",
    "\n",
    "    def _leer_txt(ruta_completa):\n",
    "        contenido = \"\"\n",
    "        try:\n",
    "            with open(ruta_completa, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                contenido = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"ADVERTENCIA: No se pudo leer el archivo de texto '{ruta_completa}'. Causa: {e}\")\n",
    "        return contenido\n",
    "\n",
    "    # Caso 1: Se especifica un archivo específico.\n",
    "    if archivo:\n",
    "        ruta_completa = os.path.join(datasets_dir, archivo)\n",
    "        if os.path.exists(ruta_completa):\n",
    "            print(f\"Leyendo archivo especificado: {ruta_completa}\")\n",
    "            if ruta_completa.lower().endswith('.pdf'):\n",
    "                return _leer_pdf(ruta_completa)\n",
    "            elif ruta_completa.lower().endswith('.txt'):\n",
    "                return _leer_txt(ruta_completa)\n",
    "            else:\n",
    "                print(f\"ADVERTENCIA: El archivo '{archivo}' no es un PDF ni un TXT. Ignorando.\")\n",
    "        else:\n",
    "            print(f\"ADVERTENCIA: El archivo especificado '{ruta_completa}' no existe.\")\n",
    "        return \"\"\n",
    "\n",
    "    # Caso 2: No se especifica un archivo, escanear el directorio completo.\n",
    "    elif os.path.isdir(datasets_dir):\n",
    "        print(f\"Escaneando y extrayendo texto de todos los archivos .pdf y .txt en: {datasets_dir}\")\n",
    "        textos_extraidos = []\n",
    "        for nombre_archivo in sorted(os.listdir(datasets_dir)):\n",
    "            ruta_completa = os.path.join(datasets_dir, nombre_archivo)\n",
    "            texto_actual = \"\"\n",
    "            if nombre_archivo.lower().endswith('.pdf'):\n",
    "                texto_actual = _leer_pdf(ruta_completa)\n",
    "            elif nombre_archivo.lower().endswith('.txt'):\n",
    "                texto_actual = _leer_txt(ruta_completa)\n",
    "            \n",
    "            if texto_actual and texto_actual.strip():\n",
    "                print(f\"  Extraído: {nombre_archivo}\")\n",
    "                textos_extraidos.append(texto_actual)\n",
    "        \n",
    "        if textos_extraidos:\n",
    "            print(f\"Se extrajo texto de {len(textos_extraidos)} archivo(s) con contenido válido.\")\n",
    "            return \"\\n\".join(textos_extraidos) # Unir todo el texto en una sola cadena.\n",
    "        else:\n",
    "            print(\"ADVERTENCIA: No se encontraron archivos .pdf o .txt con contenido válido en el directorio.\")\n",
    "            return \"\"\n",
    "    \n",
    "    # Caso 3: Ni archivo específico ni directorio válido.\n",
    "    else:\n",
    "        print(f\"ADVERTENCIA: Ni el archivo '{archivo}' ni el directorio '{datasets_dir}' son válidos.\")\n",
    "        return \"\"\n",
    "\n",
    "# 2. Convertir texto en corpus (Optimizado)\n",
    "def preparar_corpus(texto):\n",
    "    \"\"\"\n",
    "    Prepara un corpus a partir de un bloque de texto usando un generador y StringIO\n",
    "    para mayor eficiencia de memoria, procesando el texto línea por línea.\n",
    "    \"\"\"\n",
    "    # Usar io.StringIO para tratar la cadena de texto como un archivo en memoria\n",
    "    text_stream = io.StringIO(texto)\n",
    "    for linea in text_stream:\n",
    "        linea_limpia = linea.strip()\n",
    "        if linea_limpia:\n",
    "            yield simple_preprocess(linea_limpia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e8e5572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando extracción de texto...\n",
      "Escaneando y extrayendo texto de todos los archivos .pdf y .txt en: ../DataSets\n",
      "  Extraído: 217c0e1e65d907aa506a9515762adff3.pdf\n",
      "  Extraído: MANUALBASICOPARAELMANEJODEINVERNADEROS.pdf\n",
      "  Extraído: Manual de Control de Clima.pdf\n",
      "  Extraído: control_clima_riego_invernadero.txt\n",
      "  Extraído: guiadeinvernaderos.pdf\n",
      "  Extraído: inta_-_invernaderos.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P17223' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P17225' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P17291' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P17293' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P17295' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P17297' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P17299' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extraído: libro-invernaderos-de-mexico.pdf\n",
      "Se extrajo texto de 7 archivo(s) con contenido válido.\n"
     ]
    }
   ],
   "source": [
    "# --- PROCESO ---\n",
    "print('Iniciando extracción de texto...')\n",
    "texto = extraer_texto(ARCHIVO, DATASETS)\n",
    "with open(\"inv.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51139056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto extraído. Preparando corpus...\n"
     ]
    }
   ],
   "source": [
    "if texto and texto.strip():\n",
    "    print('Texto extraído. Preparando corpus...')\n",
    "    corpus = preparar_corpus(texto)\n",
    "else:\n",
    "    print('No se pudo extraer texto. El corpus no será generado.')\n",
    "    corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34115482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n",
      "Materializando el corpus en memoria para el entrenamiento...\n",
      "Corpus materializado. 18403 documentos listos para entrenar.\n",
      "Época 1/50 finalizada.\n",
      "Época 2/50 finalizada.\n",
      "Época 3/50 finalizada.\n",
      "Época 4/50 finalizada.\n",
      "Época 5/50 finalizada.\n",
      "Época 6/50 finalizada.\n",
      "Época 7/50 finalizada.\n",
      "Época 8/50 finalizada.\n",
      "Época 9/50 finalizada.\n",
      "Época 10/50 finalizada.\n",
      "Época 11/50 finalizada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 12/50 finalizada.\n",
      "Época 13/50 finalizada.\n",
      "Época 14/50 finalizada.\n",
      "Época 15/50 finalizada.\n",
      "Época 16/50 finalizada.\n",
      "Época 17/50 finalizada.\n",
      "Época 18/50 finalizada.\n",
      "Época 19/50 finalizada.\n",
      "Época 20/50 finalizada.\n",
      "Época 21/50 finalizada.\n",
      "Época 22/50 finalizada.\n",
      "Época 23/50 finalizada.\n",
      "Época 24/50 finalizada.\n",
      "Época 25/50 finalizada.\n",
      "Época 26/50 finalizada.\n",
      "Época 27/50 finalizada.\n",
      "Época 28/50 finalizada.\n",
      "Época 29/50 finalizada.\n",
      "Época 30/50 finalizada.\n",
      "Época 31/50 finalizada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 32/50 finalizada.\n",
      "Época 33/50 finalizada.\n",
      "Época 34/50 finalizada.\n",
      "Época 35/50 finalizada.\n",
      "Época 36/50 finalizada.\n",
      "Época 37/50 finalizada.\n",
      "Época 38/50 finalizada.\n",
      "Época 39/50 finalizada.\n",
      "Época 40/50 finalizada.\n",
      "Época 41/50 finalizada.\n",
      "Época 42/50 finalizada.\n",
      "Época 43/50 finalizada.\n",
      "Época 44/50 finalizada.\n",
      "Época 45/50 finalizada.\n",
      "Época 46/50 finalizada.\n",
      "Época 47/50 finalizada.\n",
      "Época 48/50 finalizada.\n",
      "Época 49/50 finalizada.\n",
      "Época 50/50 finalizada.\n"
     ]
    }
   ],
   "source": [
    "print('Iniciando entrenamiento...')\n",
    "epoch_logger = EpochLogger()\n",
    "\n",
    "# Convertir el generador del corpus a una lista para permitir múltiples pasadas\n",
    "print('Materializando el corpus en memoria para el entrenamiento...')\n",
    "corpus_list = list(corpus)\n",
    "print(f'Corpus materializado. {len(corpus_list)} documentos listos para entrenar.')\n",
    "\n",
    "modelo = Word2Vec(\n",
    "    sentences=corpus_list, # Usar la lista, no el generador\n",
    "    sg=1,  # Usar Skip-gram\n",
    "    vector_size=300,  # Aumentar dimensionalidad\n",
    "    workers=6,\n",
    "    window=8,  # Aumentar ventana de contexto\n",
    "    min_count=1,\n",
    "    epochs=50,  # Número de épocas más razonable\n",
    "    negative=10,  # Muestreo negativo\n",
    "    callbacks=[epoch_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1aab7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Guardando modelo...\n",
      "Entrenamiento finalizado.\n"
     ]
    }
   ],
   "source": [
    "print('\\nGuardando modelo...')\n",
    "modelo.save(os.path.join(PATH, MODEL))\n",
    "print(\"Entrenamiento finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
